#!/usr/bin/env python3

import os
import sys
import yaml
import httpx
import argparse
from pydantic import BaseModel, Field
from typing import Union, Literal, List

# Constants
DEFAULT_CONFIG = {
    "OLLAMA_BASE_URL": "http://localhost:11434",
    "OLLAMA_MODEL": "openhermes2.5-mistral",
    "TIMEOUT_SECONDS": 60,
    "BUFFER_SIZE": 500
}

# Define paths
home_dir = os.path.expanduser("~")
config_dir = os.path.join(home_dir, ".config", "shellai")
config_file_path = os.path.join(config_dir, "config.yaml")

# Ensure the config directory exists
os.makedirs(config_dir, exist_ok=True)

# Load configuration from config.yaml or use default config if the file doesn't exist
if os.path.exists(config_file_path):
    with open(config_file_path, 'r') as config_file:
        config_from_file = yaml.safe_load(config_file)
else:
    config_from_file = {}

config = {**DEFAULT_CONFIG, **config_from_file}

# Define role formats
SHELL_ROLE = """Provide only {current_shell} commands for {current_os} without any description.
If there is a lack of details, provide most logical solution.
Ensure the output is a valid shell command.
If multiple steps required try to combine them together using &&.
Provide only plain text without Markdown formatting.
Do not provide markdown formatting such as ```.
"""

CODE_ROLE = """Provide only code as output without any description.
Provide only code in plain text format without Markdown formatting.
Do not include symbols such as ``` or ```python.
If there is a lack of details, provide most logical solution.
You are not allowed to ask for more details.
For example if the prompt is "Hello world Python", you should return "print('Hello world')"."""

DESCRIBE_SHELL_ROLE = """Provide a terse, single sentence description of the given shell command.
Describe each argument and option of the command.
Provide short responses in about 80 words.
APPLY MARKDOWN formatting when possible."""

DEFAULT_ROLE = """You are programming and system administration assistant.
You are managing {current_os} operating system with {current_shell} shell.
Provide short responses in about 100 words, unless you are specifically asked for more details.
If you need to store any data, assume it will be stored in the conversation.
APPLY MARKDOWN formatting when possible."""

# Define a Pydantic BaseModel for Message
class Message(BaseModel):
    role: Union[Literal["system"], Literal["user"], Literal["assistant"]] # Role of the message sender
    content: str  # Content of the message

# Define a Pydantic BaseModel for ChatRequest
class ChatRequest(BaseModel):
    model: str = Field(..., alias="model")  # The type of chat model to use
    messages: List[Message] = Field(default_factory=list)  # List of messages with default factory set to empty list
    stream: bool = Field(default=False, alias="stream")  # Boolean flag indicating if streaming is enabled

# Define a Pydantic BaseModel for MessageBuffer
class MessageBuffer(BaseModel):
    system_message: Message = Field(..., alias="system_message") # The system message
    messages: List[Message] = Field(default_factory=list) # List of messages with default factory set to empty list
    buffer_size: int = Field(..., alias="buffer_size") # Size of the message buffer

    def add_message(self, message: Message):
        self.messages.append(message)

    def get_buffered_history(self) -> List[Message]:
        messages = [self.system_message]
        messages.extend(self.messages[-self.buffer_size :])
        return messages

def chat_completion(ollama_api_base: str, request: ChatRequest) -> Message:
    ollama_api_base = ollama_api_base.rstrip('/')  # Remove trailing slash from API base URL if present

    request_url = f"{ollama_api_base}/api/chat"

    request_data = request.model_dump()

    try:
        response = httpx.post(request_url, json=request_data, timeout=config["TIMEOUT_SECONDS"])
        response.raise_for_status()  # Raise HTTPError for bad status codes
        raw_message = response.json()["message"]
        message = Message(**raw_message)
    except httpx.ReadTimeout as e:
        return Message(role="assistant", content="I'm sorry, I couldn't complete the chat due to a timeout.")
    except httpx.RequestError as exc:
        return Message(role="assistant", content=f"An error occurred during the chat: {exc}")
    except Exception as e:
        return Message(role="assistant", content=f"An unexpected error occurred during the chat: {e}")

    return message

def parse_arguments():
    """Parse command-line arguments."""
    parser = argparse.ArgumentParser(description='Process user input and command-line arguments.')
    parser.add_argument('-s', '--shell', action='store_true', help='Include shell information in the message context')
    parser.add_argument('-c', '--code', dest='use_code_role', action='store_true', help='Use CODE_ROLE format')
    parser.add_argument('-d', '--describe', dest='describe_shell_role', action='store_true', help='Use DESCRIBE_SHELL_ROLE format')
    parser.add_argument('--display-config', action='store_true', help='Display current config')
    parser.add_argument('--generate-config', action='store_true', help='Generate a default config file')
    parser.add_argument('strings', nargs='*', help='Additional strings to process')

    class CustomFormatter(argparse.ArgumentDefaultsHelpFormatter, argparse.RawDescriptionHelpFormatter):
        pass

    parser.formatter_class = CustomFormatter

    example_usage = (
        "\nExample usage:\n"
        "  Generate a shell command\n"
        "    $ shellai --shell \"Generate a command to find all yaml file and delete it\"\n"
        "  Generate code \n"
        "    $ shellai --code \"Generate a function to return fibonnacci\"\n"
        "  Describe informations\n"
        "    $ git diff | shellai --describe \"Generate a git commit message\"\n"
    )

    parser.epilog = example_usage

    if len(sys.argv) <= 1:
        parser.print_help()
        sys.exit(1)

    return parser.parse_args()

def generate_config_file(file_path):
    """Generate a config.yaml file with default values."""
    if os.path.exists(file_path):
        overwrite = input("A config file already exists. Do you want to overwrite it? (yes/no): ").lower()
        if overwrite != 'yes':
            print("Aborted. Config file not overwritten.")
            return
    with open(file_path, 'w') as config_file:
        yaml.dump(DEFAULT_CONFIG, config_file)
    print("Default config.yaml file generated.")

def display_config():
    """Display the current config used."""
    print("Current Config:")
    for key, value in config.items():
        print(f"{key}: {value}")
    print()

def main():
    # Parse command-line arguments
    args = parse_arguments()

    if args.generate_config:
        generate_config_file(config_file_path)
        print("Default config.yaml file generated.")
        sys.exit(0)

    if args.display_config:
        display_config()
        sys.exit(0)  # Exit after displaying the config

    # Get current shell
    current_shell = os.environ.get('SHELL')

    # Get current operating system
    current_os = sys.platform

    # Check if there is input available from stdin
    input_text = sys.stdin.read().strip() if not sys.stdin.isatty() else ""

    # Check if there are additional strings provided
    optional_arg = ' '.join(args.strings)

    # Combine user input with command line argument
    user_message = input_text + " " + optional_arg

    # Choose the appropriate system message context based on command-line arguments
    if args.shell:
        system_message_context = SHELL_ROLE.format(current_os=current_os, current_shell=current_shell)
    elif args.use_code_role:
        system_message_context = CODE_ROLE.format(current_os=current_os, current_shell=current_shell)
    elif args.describe_shell_role:
        system_message_context = DESCRIBE_SHELL_ROLE.format(current_os=current_os, current_shell=current_shell)
    else:
        system_message_context = DEFAULT_ROLE.format(current_os=current_os, current_shell=current_shell)

    # Create a system message
    system_message = Message(role="system", content=system_message_context)

    # Create a message buffer with a system message and specified buffer size
    history_buffer = MessageBuffer(buffer_size=config["BUFFER_SIZE"], system_message=system_message)

    # Add user message to the message buffer
    history_buffer.add_message(Message(role="user", content=user_message))

    # Get buffered history of messages
    messages = history_buffer.get_buffered_history()

    # Create a chat request with Ollama model and buffered messages
    request = ChatRequest(model=config["OLLAMA_MODEL"], messages=messages)

    # Complete the chat conversation using Ollama API
    assistant_message = chat_completion(config["OLLAMA_BASE_URL"], request=request)

    # Print the content of the assistant's message
    print(assistant_message.content)

    # Add assistant's message to the message buffer
    history_buffer.add_message(assistant_message)

if __name__ == "__main__":
    main()
